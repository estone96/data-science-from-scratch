{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process(date, symbol, closing_price):\n",
    "    print (date, symbol, closing_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/20/2014 AAPL 90.91\n",
      "6/20/2014 MSFT 41.68\n",
      "6/20/2014 FB 64.5\n",
      "6/19/2014 AAPL 91.86\n",
      "6/19/2014 MSFT 41.51\n",
      "6/19/2014 FB 64.34\n"
     ]
    }
   ],
   "source": [
    "with open('tab_delimited_stock_prices.txt', 'r') as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        date = row[0]\n",
    "        symbol = row[1]\n",
    "        closing_price = float(row[2])\n",
    "        process(date, symbol, closing_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/20/2014 AAPL 90.91\n",
      "6/20/2014 MSFT 41.68\n",
      "6/20/2014 FB 64.5\n",
      "6/19/2014 AAPL 91.86\n",
      "6/19/2014 MSFT 41.51\n",
      "6/19/2014 FB 64.34\n"
     ]
    }
   ],
   "source": [
    "with open('colon_delimited_stock_prices.txt', 'r') as f:\n",
    "    reader = csv.DictReader(f, delimiter=':')\n",
    "    for row in reader:\n",
    "        date = row[\"date\"]\n",
    "        symbol = row[\"symbol\"]\n",
    "        closing_price = float(row[\"closing_price\"])\n",
    "        process(date, symbol, closing_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "today_prices = {'AAPL': 90.91, 'MSFT': 41.68, 'FB': 64.5}\n",
    "with open('comma_delimited_stock_prices.txt', 'w') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    for stock, price in today_prices.items():\n",
    "        writer.writerow([stock, price])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "html = requests.get(\"http://www.example.com\").text\n",
    "soup = BeautifulSoup(html, 'html5lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_paragraph = soup.find('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first_paragraph_text = soup.p.text\n",
    "first_paragraph_words = soup.p.text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first_paragraph_id2 = soup.p['id'] # KeyError\n",
    "first_paragraph_id2 = soup.p.get('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_paragraphs = soup.find_all('p')\n",
    "paragraph_with_ids = [p for p in soup('p') if p.get('id')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "important_paragraphs = soup('p', {'class' : 'important'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spans_inside_divs = [span for div in soup('div') for span in div('span')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = \"http://shop.oreilly.com/category/browse-subjects/data.do?sortby=publicationDate&page=1\"\n",
    "soup = BeautifulSoup(requests.get(url).text, 'html5lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "tds = soup('td', 'thumbtext')\n",
    "print (len(tds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "def is_video(td):\n",
    "    pricelabels = td('span', 'pricelabel')\n",
    "    return (len(pricelabels) == 1 and pricelabels[0].text.strip().startswith(\"Video\"))\n",
    "\n",
    "print(len([td for td in tds if not is_video(td)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def book_info(td):\n",
    "    title = td.find(\"div\", \"thumbheader\").a.text\n",
    "    by_author = td.find('div', 'AuthorName').text\n",
    "    authors = [x.strip() for x in re.sub(\"^By \", \"\", by_author).split(\",\")]\n",
    "    isbn_link = td.find(\"div\", \"thumbheader\").a.get(\"href\")\n",
    "    isbn = re.match(\"/product/(.*)\\.do\", isbn_link).group(1)\n",
    "    date = td.find(\"span\", \"directorydate\").text.strip()\n",
    "    \n",
    "    return {\n",
    "        \"title\": title, \n",
    "        \"authors\": authors,\n",
    "        \"isbn\": isbn,\n",
    "        \"date\": date\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from time import sleep\n",
    "base_url = \"http://shop.oreilly.com/category/browse-subjects/data.do?sortby=publicationDate&page=\"\n",
    "\n",
    "books = []\n",
    "\n",
    "NUM_PAGES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "souping page 1 , 0  found so far\n",
      "souping page 2 , 24  found so far\n"
     ]
    }
   ],
   "source": [
    "for page_num in range(1, NUM_PAGES + 1):\n",
    "    print (\"souping page\", page_num, \",\", len(books), \" found so far\")\n",
    "    url = base_url + str(page_num)\n",
    "    soup = BeautifulSoup(requests.get(url).text, 'html5lib')\n",
    "    \n",
    "    for td in soup('td', 'thumbtext'):\n",
    "        if not is_video(td):\n",
    "            books.append(book_info(td))\n",
    "            \n",
    "    sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_year(book):\n",
    "    return int(book[\"date\"].split()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "year_counts = Counter(get_year(book) for book in books if get_year(book) <= 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x50372f0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years = sorted(year_counts)\n",
    "book_counts = [year_counts[year] for year in years]\n",
    "plt.plot(years, book_counts)\n",
    "plt.ylabel(\"# of data books\")\n",
    "plt.title(\"Data is Big!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "endpoint = \"https://api.github.com/users/joelgrus/repos\"\n",
    "repos = json.loads(requests.get(endpoint).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates = [parse(repo[\"created_at\"]) for repo in repos]\n",
    "month_counts = Counter(date.month for date in dates)\n",
    "weekday_counts = Counter(date.weekday() for date in dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_5_repositories = sorted(repos, key=lambda r: r[\"created_at\"], reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "last_5_languages = [repo[\"language\"] for repo in last_5_repositories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from twython import Twython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitter = Twython(CONSUMER_KEY, CONSUMER_SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigDataBuzzNet : RT @EMCservices: How does your business approach #BigData? Fill the #datascientist void to drive more success https://t.co/oUPMNdJy8E https…\n",
      "\n",
      "abunchofdata : Data Science Interview Questions - https://t.co/rmXCCeSl6L #machinelearning #IoT #AI #BigData\n",
      "\n",
      "DataScienceFest : This months #DataScienceFest event is now live: hosted at Google it will sell out. Be quick! https://t.co/BbFzBCclvO\n",
      "\n",
      "7paco7 : Data Science in the Cloud, Microsoft Azure ML and Python, Free O'Reilly Media eBook https://t.co/5YD1zX4BkG via @sharethis\n",
      "#DataScience\n",
      "\n",
      "RelearnML : The Core of Data Science https://t.co/gukuOznb41  #machinelearning https://t.co/D7JPyfhCxN\n",
      "\n",
      "MariaSpiropulu : RT @NSF_MPS: #ICHEP2016 @NSF_MPSChief:“Harnessing Data Big Idea\" brings together data science, math, stats, and cyberinfrastructure.\n",
      "\n",
      "OttLegalRebels : RT @EMCservices: How does your business approach #BigData? Fill the #datascientist void to drive more success https://t.co/oUPMNdJy8E https…\n",
      "\n",
      "my_data_science : Wise Practitioner – Predictive Analytics Interview Series: Sanjay Gupta at PNC Bank https://t.co/dtPoYbMo6w #datascience\n",
      "\n",
      "my_data_science : Understanding the Bias-Variance Tradeoff: An Overview https://t.co/ZMGwgbE4Vz #datascience\n",
      "\n",
      "my_data_science : k-NN classifier for image classification https://t.co/hoESHlt1qf #datascience\n",
      "\n",
      "7paco7 : [PDF] \"DOWNLOAD\" Practical Data Science with R Free https://t.co/0WXjDperoR via @YouTube\n",
      "#DataScience\n",
      "\n",
      "HPODavidHanna : 5 free data science ebooks-Summer Reading https://t.co/6fTl4XWKWk @datasciencectrl\n",
      "\n",
      "leslieasheppard : RT @mitidss: New online course from IDSS &amp; @MITProfessional addresses data science challenges https://t.co/zvfdMbhzig https://t.co/LOSbgKSe…\n",
      "\n",
      "programmingncr : Data Science, Data Engineering Bootcamp, Seattle, Oct 10-14 Data Science Dojo is passionate about data science. We… https://t.co/9fHtmvTWYj\n",
      "\n",
      "tunguz : Doing #DataScience: Straight Talk from the Frontline  https://t.co/ql05zIlahS #ML #MachineLearning\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for status in twitter.search(q='\"data science\"')[\"statuses\"]:\n",
    "    user = status[\"user\"][\"screen_name\"]\n",
    "    text = status[\"text\"]\n",
    "    print (user, \":\", text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from twython import  TwythonStreamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyStreamer(TwythonStreamer):\n",
    "    def on_success(self, data):\n",
    "        if data['lang'] == 'en':\n",
    "            tweets.append(data)\n",
    "            print(\"received tweet #\", len(tweets))\n",
    "            \n",
    "        if len(tweets) >= 1000:\n",
    "            self.disconnect()\n",
    "            \n",
    "            \n",
    "    def on_error(self, status_code, data):\n",
    "        print(status_code, data)\n",
    "        self.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stream = MyStreamer(CONSUMER_KEY, CONSUMER_SECRET, ACCESS_TOKEN, ACCESS_TOKEN_SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "received tweet # 22\n",
      "received tweet # 23\n",
      "received tweet # 24\n",
      "received tweet # 25\n",
      "received tweet # 26\n",
      "received tweet # 27\n",
      "received tweet # 28\n",
      "received tweet # 29\n",
      "received tweet # 30\n",
      "received tweet # 31\n",
      "received tweet # 32\n",
      "received tweet # 33\n",
      "received tweet # 34\n",
      "received tweet # 35\n",
      "received tweet # 36\n",
      "received tweet # 37\n",
      "received tweet # 38\n",
      "received tweet # 39\n",
      "received tweet # 40\n",
      "received tweet # 41\n",
      "received tweet # 42\n",
      "received tweet # 43\n",
      "received tweet # 44\n",
      "received tweet # 45\n",
      "received tweet # 46\n",
      "received tweet # 47\n",
      "received tweet # 48\n",
      "received tweet # 49\n",
      "received tweet # 50\n"
     ]
    }
   ],
   "source": [
    "stream.statuses.filter(track='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_hashtags = Counter(hashtag['text'].lower() for tweet in tweets for hashtag in tweet[\"entities\"][\"hashtags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('futurehealth', 2), ('data', 2), ('bigdata', 2), ('stats', 1), ('business', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(top_hashtags.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
